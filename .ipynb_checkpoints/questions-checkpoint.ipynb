{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probit Maximum Likelihood\n",
    "\n",
    "In this homework you should implement the maximum likelihood estimator for the probit model. To remind you, this model is defined as follows:\n",
    "    $$\n",
    "    \\begin{align}  \n",
    "    y_i  &\\in \\{0,1\\} \\\\\n",
    "    \\Pr\\{y_i=1\\} &= \\Phi(x_i \\beta) \\\\\n",
    "    L(\\beta)   & = \\Pi_{i=1}^N  \\Phi(x_i \\beta)^{y_i} (1-\\Phi(x_i \\beta))^{1-y_i} \\\\\n",
    "    \\beta  & \\in \\mathbb{R}^k \\\\\n",
    "    x_i  & \\sim N\\left([0,0,0],\\left[ \\begin{array}{ccc} 1 & 0 & 0 \\\\ 0 & 1 & 0 \\\\ 0 & 0 & 1\\end{array} \\right] \\right) \\\\\n",
    "    k & = 3 \n",
    "    \\end{align}\n",
    "    $$\n",
    "    \n",
    "Where $\\Phi$ is the standard Normal cdf. Think of $x_i$ as a row-vector. You should proceed as follows:\n",
    "\n",
    "1. define a data generating function with default argument `N=10000`, generating `N` simulated data points from this model. Generate the data using $\\beta=[1,1.5,-0.5]$. The function should return a `Dict` as outlined in the code.\n",
    "1. Define the log likelihood function, $l(\\beta) = \\log(L)$\n",
    "1. Write a function `plotLike` to plot the log likelihood function for different parameter values. Follow the outline of that function.\n",
    "1. Define the function `maximize_like`. this should optimize your log likelihood function.\n",
    "1. (Optional) Define the gradient of the log likelihood function and use it in another optimization `maximize_ike_grad`.\n",
    "1. (Optional) Define the hessian of the log likelihood function and use it in another optimization `maximize_like_grad_hess`.\n",
    "1. (Optional) Use the hessian of the log likelihood function to compute the standard errors of your estimates and use it in `maximize_like_grad_se`\n",
    "\n",
    "## Tests\n",
    "\n",
    "* The code comes with a test suite that you should fill out. \n",
    "* There are some example tests, you should make those work and maybe add other ones. \n",
    "* Please do not change anything in the file structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Method definition makeData() in module Main at In[70]:5 overwritten at In[76]:5.\n",
      "WARNING: Method definition makeData(Any) in module Main at In[70]:5 overwritten at In[76]:5.\n",
      "WARNING: Method definition makeData(Any, Any) in module Main at In[70]:5 overwritten at In[76]:5.\n",
      "WARNING: Method definition makeData(Any, Any, Any) in module Main at In[70]:5 overwritten at In[76]:5.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "makeData (generic function with 4 methods)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Distributions, Optim, PyPlot, DataFrames\n",
    "\n",
    "# data generating function\n",
    "function makeData(n=10000::Int, beta = [ 1; 1.5; -0.5 ]::Vector, k=3::Int)\n",
    "    X = rand(MvNormal(eye(k)),n) # define X\n",
    "    y = Array{Int}(n) #empty y\n",
    "    for i in 1:n # define binomial y\n",
    "        y[i] = rand(Bernoulli(cdf(Normal(),dot(X[:,i]',beta))))\n",
    "    end\n",
    "    # return a dict with beta,numobs,X,y,norm)\n",
    "    return Dict(\"beta\" => beta, \"numobs\" => n, \"X\" => X, \"y\" => y, \"dist\" => Normal())\n",
    "    #return beta, X, y\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{String,Any} with 5 entries:\n",
       "  \"y\"      => [1,0,0,1,0,1,0,0,1,1  …  1,0,0,0,0,1,1,1,1,0]\n",
       "  \"X\"      => [0.506386 0.179857 … 0.107167 -0.330175; 0.431269 -0.273457 … 1.0…\n",
       "  \"numobs\" => 10000\n",
       "  \"dist\"   => Distributions.Normal{Float64}(μ=0.0, σ=1.0)\n",
       "  \"beta\"   => [1.0,1.5,-0.5]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "makeData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loglik (generic function with 2 methods)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function loglik(beta::Vector, d::Dict)\n",
    "    l = 0\n",
    "    for i in 1:d[\"numobs\"]\n",
    "        if d[\"y\"][i] == 1\n",
    "            l = l + log(cdf(d[\"dist\"],dot(d[\"X\"][:,i]',beta)))\n",
    "        else\n",
    "            l = l + log(1-cdf(d[\"dist\"],dot(d[\"X\"][:,i]',beta)))\n",
    "        end\n",
    "    end\n",
    "    return l\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3406.366194758875"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function plotLike()\n",
    "    d = makeData()\n",
    "    l1(x) = loglik([ x d[\"beta\"][2] d[\"beta\"][3]], d)\n",
    "            \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3384.672588244844"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = makeData()\n",
    "loglik(d[\"beta\"],d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.5.0",
   "language": "julia",
   "name": "julia-0.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
